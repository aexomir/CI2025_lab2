# TSP Optimization: Hill Climbing vs Evolutionary Computation

A comprehensive benchmarking framework comparing two meta-heuristic algorithms for solving the Traveling Salesman Problem (TSP).

## ğŸ“Š Executive Summary

This project implements and compares two optimization approaches on 22 TSP problem instances:

- **Hill Climbing (HC)** with Simulated Annealing
- **Evolutionary Computation (EC)** with tournament selection and genetic operators

### Key Results

| Metric                               | Value                   |
| ------------------------------------ | ----------------------- |
| **Total Problems Tested**            | 22 instances            |
| **Average HC Execution Time**        | 0.51 seconds            |
| **Average EC Execution Time**        | 59.40 seconds           |
| **Average Improvement (EC over HC)** | 3.99%                   |
| **Best Improvement Achieved**        | 31.36% (problem_r1_200) |

**Performance Highlights:**

- EC significantly outperforms HC on `r1_*` problem types (average 21.59% improvement)
- EC shows mixed results on `r2_*` problems (some degradation due to problem characteristics)
- HC is ~116x faster but less accurate
- EC's longer runtime trades speed for solution quality

---

## ğŸ—ï¸ Project Structure

```
CI/lab2/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ RESULTS_FORMAT.md           # Detailed results documentation
â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚
â”œâ”€â”€ lab_problems/               # TSP problem instances (.npy files)
â”‚   â”œâ”€â”€ problem_g_10.npy       # Geometric problems (10-1000 nodes)
â”‚   â”œâ”€â”€ problem_r1_10.npy      # Random type 1 problems
â”‚   â”œâ”€â”€ problem_r2_10.npy      # Random type 2 problems
â”‚   â””â”€â”€ test_problem.npy       # Test instance
â”‚
â”œâ”€â”€ src/                        # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main_runner.py         # Entry point for benchmarking
â”‚   â”‚
â”‚   â”œâ”€â”€ data_problems/         # Data structures
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ solution.py        # Solution and SolutionResults classes
â”‚   â”‚
â”‚   â”œâ”€â”€ solvers/               # Algorithm implementations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ hc_solver.py       # Hill Climbing + Simulated Annealing
â”‚   â”‚   â””â”€â”€ ec_solver.py       # Evolutionary Computation
â”‚   â”‚
â”‚   â””â”€â”€ utils/                 # Utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ test_solvers.py    # Benchmarking framework
â”‚
â”œâ”€â”€ results/                    # Output directory
â”‚   â”œâ”€â”€ global_summary.csv     # Aggregated results
â”‚   â”œâ”€â”€ problem_*_summary.csv  # Per-problem HC vs EC comparison
â”‚   â”œâ”€â”€ problem_*_ec_results.csv   # Detailed EC configurations
â”‚   â””â”€â”€ *.npy                  # Binary result objects
â”‚
â””â”€â”€ notebooks/                  # Jupyter notebooks for analysis
    â”œâ”€â”€ 01_analysis.ipynb
    â””â”€â”€ 02_custom_test.ipynb
```

---

## ğŸ§® Algorithms

### 1. Hill Climbing (HC) with Simulated Annealing

**Algorithm Type:** Local Search with Metropolis Criterion

**Key Components:**

- **Initialization:** Epsilon-greedy nearest neighbor (10% random, 90% greedy)
- **Neighborhood:** 2-opt swaps (reverses tour segments)
- **Acceptance:** Simulated Annealing schedule
  - Temperature: `T = 0.1 * (MAX_ITER - CUR_ITER) / MAX_ITER`
  - Accept worse solutions with probability: `exp(-Î”fitness / T)`
- **Iterations:** 10,000 fixed

**Characteristics:**

- âœ… Fast execution (~0.5s average)
- âœ… Simple, easy to implement
- âœ… Guaranteed local optima
- âš ï¸ May get trapped in local minima
- âš ï¸ Performance depends on initial solution

**Implementation:** `src/solvers/hc_solver.py`

- `epsilon_greedy_initialization()` - Creates starting tour
- `two_opt_move()` - Generates neighbors
- `simulated_annealing_solver()` - Main algorithm

---

### 2. Evolutionary Computation (EC)

**Algorithm Type:** Population-based Evolutionary Strategy

**Key Components:**

- **Population:** Mixed initialization (70% greedy, 30% random)
- **Selection:** Tournament selection (Ï„ = 10% of population)
- **Crossover:** Order Crossover (OX) - preserves tour validity
- **Mutation:** Swap mutation (probability: 0.1-0.3)
- **Survival:** Two strategies tested
  - `(Î¼+Î»)` - Elitist: best from parents + offspring
  - `(Î¼,Î»)` - Non-elitist: best from offspring only

**Parameters Tested:**

- Population sizes: 50, 100, 150
- Offspring sizes: 100, 200, 300
- Mutation rates: 0.1, 0.2, 0.3
- Generations: 100
- **Total configurations:** 54 (3Ã—3Ã—3Ã—2)

**Characteristics:**

- âœ… Explores solution space globally
- âœ… Less prone to local optima
- âœ… Better solution quality on average
- âš ï¸ Computationally expensive (~60s average)
- âš ï¸ Requires parameter tuning

**Implementation:** `src/solvers/ec_solver.py`

- `tournament_selection()` - Parent selection
- `order_crossover_ox()` - Recombination
- `swap_mutation()` - Variation
- `ec_solver()` - Main evolutionary loop

---

## ğŸ“ˆ Results Analysis

### Performance by Problem Type

#### **Geometric Problems (`g_*`)**

Average improvement: **4.76%**

| Problem | Nodes | HC Fitness | EC Fitness | Improvement | EC Time (s) |
| ------- | ----- | ---------- | ---------- | ----------- | ----------- |
| g_10    | 10    | 1497.66    | 1497.66    | 0.00%       | 0.37        |
| g_20    | 20    | 1809.41    | 1755.51    | 2.98%       | 0.43        |
| g_50    | 50    | 2867.87    | 2723.55    | 5.03%       | 2.52        |
| g_100   | 100   | 4513.63    | 4435.11    | 1.74%       | 1.36        |
| g_200   | 200   | 7992.89    | 7502.23    | 6.14%       | 4.66        |
| g_500   | 500   | 16658.68   | 15984.43   | 4.05%       | 98.69       |
| g_1000  | 1000  | 35085.07   | 30055.45   | **14.34%**  | 344.77      |

**Insight:** EC shows increasing advantage with problem size, achieving 14% improvement on the largest instance.

---

#### **Random Type 1 Problems (`r1_*`)**

Average improvement: **21.59%** ğŸ† **BEST PERFORMANCE**

| Problem | Nodes | HC Fitness | EC Fitness | Improvement | EC Time (s) |
| ------- | ----- | ---------- | ---------- | ----------- | ----------- |
| r1_10   | 10    | 214.38     | 184.27     | 14.05%      | 0.36        |
| r1_20   | 20    | 382.81     | 337.29     | 11.89%      | 1.29        |
| r1_50   | 50    | 717.82     | 561.29     | 21.81%      | 2.26        |
| r1_100  | 100   | 978.98     | 802.69     | 18.01%      | 3.22        |
| r1_200  | 200   | 1865.98    | 1280.75    | **31.36%**  | 8.62        |
| r1_500  | 500   | 3694.75    | 2891.18    | 21.75%      | 71.57       |
| r1_1000 | 1000  | 7631.20    | 5320.89    | 30.27%      | 372.21      |

**Insight:** EC excels on r1 problems, suggesting these instances have complex fitness landscapes where population-based search is superior.

---

#### **Random Type 2 Problems (`r2_*`)**

Average improvement: **-14.72%** âš ï¸ (EC performs worse)

| Problem | Nodes | HC Fitness | EC Fitness | "Improvement" | EC Time (s) |
| ------- | ----- | ---------- | ---------- | ------------- | ----------- |
| r2_10   | 10    | -340.01    | -411.70    | -21.09%       | 0.85        |
| r2_20   | 20    | -691.08    | -845.41    | -22.33%       | 1.02        |
| r2_50   | 50    | -1799.69   | -2244.77   | -24.73%       | 0.67        |
| r2_100  | 100   | -4233.80   | -4621.46   | -9.16%        | 5.52        |
| r2_200  | 200   | -8319.95   | -9432.65   | -13.37%       | 9.74        |
| r2_500  | 500   | -21618.32  | -23401.71  | -8.25%        | 101.32      |
| r2_1000 | 1000  | -43939.12  | -46608.67  | -6.08%        | 274.57      |

**Insight:** Negative fitness values indicate r2 problems are maximization with sign flip. EC's population diversity may be less effective on these smoother landscapes where HC's local search excels.

---

### Optimal EC Configurations

**Most Common Winners:**

- **Strategy:** `(Î¼,Î»)` won on 16/22 problems (non-elitist performs better)
- **Population:** Mixed (50-150), problem-dependent
- **Offspring:** Larger populations (200-300) preferred for complex problems

**Configuration Frequency:**

```
(Î¼,Î») with pop=150, offspring=300: 8 wins  (best for large/complex)
(Î¼,Î») with pop=50,  offspring=200: 4 wins  (good for medium)
(Î¼+Î») with pop=50,  offspring=100: 3 wins  (fast, small problems)
```

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/aexomir/CI2025_lab2

# Install dependencies
pip install -r requirements.txt
```

### Running Benchmarks

```bash
# Full benchmark (54 EC configurations per problem)
python src/main_runner.py

# Quick test (16 EC configurations)
python -c "
from src.utils.test_solvers import run_benchmarks
run_benchmarks(ec_config='easy')
"
```

### Analyzing Results

```python
import pandas as pd

# Load global summary
df = pd.read_csv('results/global_summary.csv')

# View top improvements
top5 = df.nlargest(5, 'ec_improvement')
print(top5[['problem', 'hc_fitness', 'ec_best_fitness', 'ec_improvement']])

# Analyze EC configurations for a problem
ec_details = pd.read_csv('results/problem_r1_200_ec_results.csv')
best = ec_details.nsmallest(5, 'best_fitness')
print(best[['best_fitness', 'execution_time', 'strategy', 'population_size']])
```

---

## ğŸ“ Output Files

### Per-Problem Files

- `{problem}_hc_results.npy` - Binary HC results
- `{problem}_ec_best_results.npy` - Binary best EC results
- `{problem}_ec_all_results.npy` - All 54 EC configurations
- `{problem}_summary.csv` - HC vs EC comparison
- `{problem}_ec_results.csv` - Detailed EC configurations

### Global Summary

- `global_summary.csv` - Aggregated results across all problems

See `RESULTS_FORMAT.md` for detailed file format documentation.

---

## ğŸ¯ Key Takeaways

1. **EC vs HC Trade-off:**

   - EC provides 4% average improvement at 116x time cost
   - ROI depends on problem size and quality requirements

2. **Problem-Specific Performance:**

   - EC strongly recommended for `r1_*` type problems (21% improvement)
   - HC sufficient for `r2_*` problems (faster, competitive results)
   - EC scales better with problem size

3. **Parameter Selection:**

   - `(Î¼,Î»)` strategy generally outperforms `(Î¼+Î»)`
   - Larger offspring populations (200-300) beneficial for complex instances
   - Mutation rate 0.1-0.2 works well across problems

4. **Practical Recommendations:**
   - Use HC for: Real-time applications, small problems (<100 nodes), r2-type landscapes
   - Use EC for: High-quality solutions needed, r1-type problems, large instances (>500 nodes)

---

## ğŸ”¬ Technical Details

### TSP Representation

- **Encoding:** Permutation of city indices [0, 1, ..., N-1]
- **Fitness:** Total tour length (Euclidean distance sum + return to start)
- **Objective:** Minimization

### Computational Environment

- **Language:** Python 3.8+
- **Parallelization:** joblib (all CPU cores for EC configurations)
- **Random Seed:** 42 (for reproducibility)

### Benchmarking Methodology

1. Load TSP instance from `.npy` file
2. Run HC solver (single run, 10,000 iterations)
3. Run 54 EC configurations in parallel
4. Record best fitness and execution time
5. Save results in multiple formats (binary + CSV)

**Total Runtime (22 problems):** ~22 minutes (HC: 11s, EC: 1307s)

## Acknowledgements / Ethical Note

This project drew comparative HC vs EC benchmarking idea from https://github.com/DjangoRepoMngr/CI2025_lab2;

AI assistants were used to brainstorm structure and minor refinements, but all algorithms, parameter choices, and source code were authored independently without copyingâ€”this attribution clarifies influence and ethical use of external and AI resources.
